---
title: "Sequence Autoencoders"
output: html_notebook
---

```{r setup}
knitr::opts_knit$set(root.dir = '/home/harpo/hostdir/ia-dojo-repo/experiments/dga-gen/')
```

```{r message=FALSE, warning=FALSE}
library(keras)
library(tensorflow)
```


```{r}
source("code/R/functions/dgagen-helpers.R")
```
# Read domains
```{r eval=FALSE, include=FALSE}
library(urltools)
gc()
text <- readr::read_csv("rawdata/argencon.csv.gz")
text<-text %>% filter(grepl("normal",label))
text<-text %>% sample_frac(0.1)
domains <-  text %>% pull(domain)
domains <- domains %>% urltools::host_extract()
domains <- domains  %>% tidyr::drop_na() %>% pull(host)
```
```{r}
text <- readr::read_csv("rawdata/argencon.csv.gz")
text<-text %>% tidyr::separate(label,c("label","family"))
#text<-text %>% filter(grepl("normal",label))
text<-text %>% group_by(family)%>% sample_frac(0.05)
domains <-  text %>% pull(domain)
domains <- domains %>% urltools::host_extract()
domains <- domains  %>% tidyr::drop_na() %>% pull(host)
```

```{r}
sentences_tokenized<-tokenize(domains %>% as.matrix, "n",maxlen)
shape <- c(nrow(sentences_tokenized$x), maxlen, length(valid_characters_vector))
seq_x<-to_onehot(sentences_tokenized$x,shape)
seq_x[1,,]
```

## Check one_hot
```{r}
dimen<-seq_x %>% dim()
enc<-""
for (i in 0:dimen[2]  ){
#      print(i)
      enc<-str_c(enc,valid_characters_vector[which.max(seq_x[1,i,])])
}
enc
```
 
```{r}
dim (seq_x)
```
 
## Sequence Autoencoder 
```{r eval=FALSE, include=FALSE}
# This is the size of our encoded representations
encoding_dim <- c(10, 8)

input_size <-  c(maxlen, length(valid_characters_vector))
## ENCODER
enc_input <- layer_input(shape = input_size)
enc_output <- enc_input %>% 
  layer_conv_1d(
  filters = 16,
  kernel_size = 3,
  activation = 'relu',
  padding = 'valid',
  strides = 1
) %>%
 layer_max_pooling_1d(pool_size = 2, padding = 'same') %>%
 layer_conv_1d(
   filters = 8,
   kernel_size = 3,
   activation = 'relu',
   padding = 'same',
   strides = 1
 ) %>%
 layer_max_pooling_1d(pool_size = 2, padding = 'same')

## DECODER
dec_input <- layer_input(shape = encoding_dim)

dec_output <-   dec_input %>%
  layer_conv_1d(
    filters = 8,
    kernel_size = 3,
    activation = 'relu',
    padding = 'same',
    strides = 1
  ) %>%
  layer_upsampling_1d(size = 2) %>%
 
 layer_conv_1d(
    filters = 16,
    kernel_size = 3,
    activation = 'relu',
    padding = 'same',
    strides = 1
  ) %>%
  layer_upsampling_1d(size = 2)   %>%
  layer_dense(44, activation = 'sigmoid')


encoder <- keras_model(enc_input, enc_output,name ="encoder")
decoder <- keras_model(dec_input, dec_output,name ="decoder")

encoder
decoder
```
## LSTM sequence Autoencoder

```{r}

input_size <-  c(maxlen, length(valid_characters_vector))
latent_dim <- 64 
## ENCODER
enc_input <- layer_input(shape = input_size) 
enc_output <- enc_input %>% 
  layer_masking(mask_value = 0) %>%
  layer_lstm(latent_dim)

## DECODER
dec_input <- layer_input(shape = latent_dim)
dec_output <-   dec_input %>% 
                layer_repeat_vector(maxlen) %>%
                layer_lstm(valid_characters_vector %>% length(), return_sequences = TRUE) %>%
                layer_dense(valid_characters_vector %>% length(),activation = 'softmax')
               #$ outputs = TimeDistributed(Dense(vocab_size, activation='softmax'))(decoder1)
  
auto_encoder <- keras_model(enc_input, enc_output,name ="encoder")
auto_decoder <- keras_model(dec_input, dec_output,name ="decoder")

auto_encoder
auto_decoder
```


```{r}

autoencoder_input <- layer_input(shape = input_size,name="ae_input")
autoencoder_output <- autoencoder_input %>% 
  auto_encoder() %>% 
  auto_decoder()
autoencoder <- keras_model(autoencoder_input, autoencoder_output,name="autoencoder")
optimizer <- optimizer_adam(learning_rate = 0.005)
autoencoder %>% compile(optimizer= optimizer, loss='mse')
autoencoder
```
 
```{r}
autoencoder %>% fit(seq_x, seq_x,
                epochs=15,
                batch_size=512)
```
```{r}
#save_model_tf(decoder,"../../../models/dgagen-decoder.keras")
```
 
```{r}
#decoder_b <- load_model_tf("../../../models/dgagen-decoder.keras")
```


```{r eval=FALSE, include=FALSE}
library(lubridate)
#autoencoder$get_layer("decoder") %>% get_weights()

d<-domains[5]

mdate<-( lubridate::now() + lubridate::days(2) ) %>% as.character()  %>% gsub(x=.,"[:-]","")

mdate<-(now() %>% as.integer())
d<-paste0(mdate)
d
```


```{r}
d<-domains[5]
print(d)
vectorized_test <- tokenize(d, "n", maxlen)
      shape = c(nrow(vectorized_test$x),
                maxlen,
                length(valid_characters_vector))
vectorized_test <- to_onehot(vectorized_test$x, shape)
preds_encoder <- auto_encoder(vectorized_test)

preds_encoder<- preds_encoder %>%  as.array() 

#preds_encoder[1]    <- preds_encoder[1]+rnorm(1,mean=0, sd= 1)  
#preds_encoder[5]    <- preds_encoder[5]+rnorm(1,mean=0, sd= 1)  
#preds_encoder[10]    <- preds_encoder[10]+rnorm(1,mean=0, sd= 1)  
#preds_encoder[15]    <- preds_encoder[15]+rnorm(1,mean=0, sd= 1)  
#preds_encoder[25]    <- preds_encoder[25]+rnorm(1,mean=0, sd= 1)  
#vectorized_test[1,,]


eps<-runif(latent_dim,-1,1) %>% as_tensor()
z <- tf$add(eps,preds_encoder)
z %>% dim()
decoded <- auto_decoder(z) 
dim(decoded)

#preds[1,2,] %>% which.max()
#valid_characters_vector[16]
dimen<- decoded %>% dim()
enc<-""
for (i in 1:dimen[2]  ){
#      print(i)
      enc<-str_c(enc,
                 valid_characters_vector[which.max(decoded[1,i,] %>% as.matrix())]
                 
                 )
}
print(substr(enc, start = 1,stop =nchar(d) ) )

```
```{r}
library(ggplot2)
encoded_seq_x <-predict(auto_encoder, seq_x)
encoded_seq_x_mean<-encoded_seq_x
```


```{r}
encoded_seq_x_mean[,29] %>% as.data.frame() %>%
  ggplot()+
  geom_histogram(aes(x=.),fill='skyblue',color='white') +
  theme_classic()

```
### UMAP
```{r}
#umap_data_auto <- umap(encoded_seq_x_mean)

nrow(umap_data_auto$layout)
text_reduce<-text %>% head(nrow(umap_data_auto$layout))
domains_data_umap_auto <- data.frame(umap_data_auto$layout, family = text_reduce$family)
```


```{r fig.height=8, fig.width=8}
#head(umap_data$layout) %>% as.data.frame()
ggplot(domains_data_umap_auto %>% sample_frac(0.1)) +
  geom_point(aes(x=X1,y=X2,color=family),alpha=0.9,size=2)+#,shape =1 ) +
  theme(legend.position = NULL) +
  labs(subtitle = "Autoencoder: Latent space 2D projection (UMAP) (zoomed-in view)",title="DOMAIN NAMES FAMILIES")+
  ylim(-5,5)+
  xlim(-6,5)+
  ylab("")+
  xlab("")+
  theme_classic()+
  ggdark::dark_theme_classic()+
  theme(legend.position = "none")

```
### PCA

```{r}
pca_data_auto<- prcomp(encoded_seq_x_mean)
nrow(pca_data_auto$x)
text_reduce<-text %>% head(nrow(pca_data_auto$x))
domains_data_pca_auto <- data.frame(pca_data_auto$x, family=text_reduce$family)
```
```{r}
ggplot(domains_data_pca_auto %>% sample_frac(0.1)) +
  geom_point(aes(x=PC2,y=PC3,color=family),alpha=0.5,size=2) +
  theme(legend.position = NULL) +
  ylim(-2,2)+
  xlim(-2,2)+
  theme_classic()
#plotly::ggplotly()
```
 
 
---
title: "R Notebook"
output: html_notebook
---
```{r message=FALSE, warning=FALSE}
library(keras)
library(tensorflow)
```

```{r}
## -------------------------------------------------------------------------
latent_dim <- 2

encoder_inputs <-  layer_input(shape=c(28, 28, 1))
x <- encoder_inputs %>%
  layer_conv_2d(32, 3, activation = "relu", strides = 2, padding = "same") %>%
  layer_conv_2d(64, 3, activation = "relu", strides = 2, padding = "same") %>%
  layer_flatten() %>%
  layer_dense(16, activation = "relu")
z_mean    <- x %>% layer_dense(latent_dim, name="z_mean")
z_log_var <- x %>% layer_dense(latent_dim, name="z_log_var")
encoder <- keras_model(encoder_inputs, list(z_mean, z_log_var),
                       name="encoder")
```


```{r}
## -------------------------------------------------------------------------
encoder
```


```{r}
## -------------------------------------------------------------------------
layer_sampler <- new_layer_class(
  classname = "Sampler",
  call = function(self, z_mean, z_log_var) {
    epsilon <- tf$random$normal(shape = tf$shape(z_mean))
    z_mean + exp(0.5 * z_log_var) * epsilon
  }
)
```


```{r}
## -------------------------------------------------------------------------
latent_inputs <- layer_input(shape = c(latent_dim))
decoder_outputs <- latent_inputs %>%
  layer_dense(7 * 7 * 64, activation = "relu") %>%
  layer_reshape(c(7, 7, 64)) %>%
  layer_conv_2d_transpose(64, 3, activation = "relu",
                          strides = 2, padding = "same") %>%
  layer_conv_2d_transpose(32, 3, activation = "relu",
                          strides = 2, padding = "same") %>%
  layer_conv_2d(1, 3, activation = "sigmoid", padding = "same")
decoder <- keras_model(latent_inputs, decoder_outputs,
                       name = "decoder")
```


```{r}

decoder
```


```{r}
## -------------------------------------------------------------------------
model_vae <- new_model_class(
  classname = "VAE",

  initialize = function(encoder, decoder, ...) {
    super$initialize(...)
    self$encoder <- encoder
    self$decoder <- decoder
    self$sampler <- layer_sampler()
    self$total_loss_tracker <-
      metric_mean(name = "total_loss")
    self$reconstruction_loss_tracker <-
      metric_mean(name = "reconstruction_loss")
    self$kl_loss_tracker <-
      metric_mean(name = "kl_loss")
  },

  metrics = mark_active(function() {
    list(
      self$total_loss_tracker,
      self$reconstruction_loss_tracker,
      self$kl_loss_tracker
    )
  }),

  train_step = function(data) {
    with(tf$GradientTape() %as% tape, {

      c(z_mean, z_log_var) %<-% self$encoder(data)
      z <- self$sampler(z_mean, z_log_var)

      reconstruction <- decoder(z)
      reconstruction_loss <-
        loss_binary_crossentropy(data, reconstruction) %>%
          sum(axis = c(2, 3)) %>%
          mean()

      kl_loss <- -0.5 * (1 + z_log_var - z_mean^2 - exp(z_log_var))
      total_loss <- reconstruction_loss + mean(kl_loss)
    })

    grads <- tape$gradient(total_loss, self$trainable_weights)
    self$optimizer$apply_gradients(zip_lists(grads, self$trainable_weights))

    self$total_loss_tracker$update_state(total_loss)
    self$reconstruction_loss_tracker$update_state(reconstruction_loss)
    self$kl_loss_tracker$update_state(kl_loss)

    list(total_loss = self$total_loss_tracker$result(),
         reconstruction_loss = self$reconstruction_loss_tracker$result(),
         kl_loss = self$kl_loss_tracker$result())
  }
)
```


```{r}
## -------------------------------------------------------------------------
library(listarrays)
c(c(x_train, .), c(x_test, .)) %<-% dataset_mnist()

mnist_digits <-
  bind_on_rows(x_train, x_test) %>%
  expand_dims(-1) %>%
  { . / 255 }

str(mnist_digits)

vae <- model_vae(encoder, decoder)
vae %>% compile(optimizer = optimizer_adam())


## -------------------------------------------------------------------------
vae %>% fit(mnist_digits, epochs = 30, batch_size = 128)


## -------------------------------------------------------------------------
```


```{r}
n <- 30

digit_size <- 28

z_grid <-
  seq(-1, 1, length.out = n) %>%
  expand.grid(., .) %>%
  as.matrix()

decoded <- predict(vae$decoder, z_grid)

z_grid_i <- seq(n) %>% expand.grid(x = ., y = .)
figure <- array(0, c(digit_size * n, digit_size * n))
for (i in 1:nrow(z_grid_i)) {
  c(xi, yi) %<-% z_grid_i[i, ]
  digit <- decoded[i, , , ]
  figure[seq(to = (n + 1 - xi) * digit_size, length.out = digit_size),
         seq(to = yi * digit_size, length.out = digit_size)] <-
    digit
}


```


```{r fig.height=12, fig.width=12}
par(pty = "s")
lim <- extendrange(r = c(-1, 1),
                   f = 1 - (n / (n+.5)))
plot(NULL, frame.plot = FALSE,
     ylim = lim, xlim = lim,
     xlab = ~z[1], ylab = ~z[2])
rasterImage(as.raster(1 - figure, max = 1),
            lim[1], lim[1], lim[2], lim[2],
            interpolate = FALSE)

```

